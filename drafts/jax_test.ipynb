{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from common.jupyter_animation import animate, animation_table\n",
    "from typing import Iterable, Union, Callable, Tuple, List, Dict, Any\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode=\"rgb_array\")\n",
    "env.reset()\n",
    "image_seq = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "while not done:\n",
    "  observation, reward, done, truncated, info = env.step(env.action_space.sample())\n",
    "  image_seq.append(env.render())\n",
    "\n",
    "animate(image_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_state(space_obj, num_bins:Iterable[int], return_indexi=False, max_value=1024) -> Callable:\n",
    "  bins = [np.linspace(max(low, -max_value), min(high, max_value), num=num_bin) for low, high, num_bin in zip(space_obj.low, space_obj.high, num_bins)]\n",
    "\n",
    "  def discretize_state_fn(input_state:np.ndarray) -> np.ndarray:\n",
    "    discretized_state = np.zeros(input_state.shape)\n",
    "    discretized_indexi = np.zeros(input_state.shape, dtype=np.int32)\n",
    "    for i, bin_space in enumerate(bins):\n",
    "      discrete_index = np.digitize(input_state[i], bin_space)-1\n",
    "      discretized_state[i] = bins[i][discrete_index]\n",
    "      discretized_indexi[i] = discrete_index\n",
    "    \n",
    "    ret = discretized_state if not return_indexi else discretized_indexi\n",
    "    ret = tuple(ret)\n",
    "    return ret\n",
    "\n",
    "  return discretize_state_fn\n",
    "\n",
    "# discret_func = discretize_state(env.observation_space, num_bins=(10, 10, 10, 10))\n",
    "# discret_func(np.array([-4.8, -100, 1, -10]))\n",
    "# discret_func(np.array([5, 2000, 0.1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.1\n",
    "max_epoch = 100000\n",
    "\n",
    "discret_func = discretize_state(env.observation_space, num_bins=(30, 30, 50, 50), return_indexi=True)\n",
    "q_table = np.zeros((30, 30, 50, 50, 2))\n",
    "all_steps_taken = []\n",
    "truncated = False\n",
    "\n",
    "\n",
    "for i in range(1, max_epoch):\n",
    "  state = discret_func(env.reset()[0])\n",
    "  done = False\n",
    "  steps_taken = 0\n",
    "\n",
    "  # trace\n",
    "  while not done and not truncated:\n",
    "    if np.random.uniform(0 ,1) < epsilon:\n",
    "      action = env.action_space.sample()\n",
    "    else:\n",
    "      action = np.argmax(q_table[state])\n",
    "\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    next_state = discret_func(next_state)\n",
    "\n",
    "    q_value = q_table[state, action]\n",
    "    next_max = np.max(q_table[next_state])\n",
    "\n",
    "    new_q_value = (1 - alpha) * q_value + alpha * (reward + gamma * next_max)\n",
    "    q_table[state, action] = new_q_value\n",
    "\n",
    "    state = next_state\n",
    "    steps_taken += 1\n",
    "  \n",
    "  all_steps_taken.append(steps_taken)\n",
    "  \n",
    "  if i % 100 == 0:\n",
    "    print(f\"Average steps taken for the past 10 epochs: {sum(all_steps_taken[-10:]) / 10}\")\n",
    "\n",
    "print(\"Training finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total elements: \", q_table.size)\n",
    "print(\"q vlaue >= 0.5: \", np.count_nonzero(q_table >= 0.5))\n",
    "print(\"q vlaue < 0.5: \", np.count_nonzero(q_table < 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('RL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "25f36fc7060c5fa438d5d5ba87fb1f9d2eb086d328c20a03575dd46406d78752"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
